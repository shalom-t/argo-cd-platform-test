#############################################
# Superset helm chart additional values file #
#############################################

# Image configuration - override default image tag
image:
  tag: 6.0.0rc2

# Service configuration
service:
  # Service type is ClusterIP
  # Reason: Exposes Superset service internally within the Kubernetes cluster.
  # This is typical for applications accessed behind an ingress or reverse proxy,
  # instead of direct external access.
  type: ClusterIP
  # Port where Superset listens internally
  # Reason: Superset's default web server runs on 8088.
  port: 8088 # 8088 is the default port for Superset

# Extra environment variables (key-value format)
# Note: ROW_LIMIT is set in configOverrides.secret below (Superset Python config)
extraEnv: {}

# Extra environment variables in RAW format
extraEnvRaw:
  - name: EMAIL_NOTIFICATIONS
    value: "True"
  - name: SMTP_HOST
    # value: "192.168.100.111" # ðŸ‘ˆ your host IP
    value: "192.168.1.233"
  - name: SMTP_PORT
    value: "1025"
  - name: SMTP_STARTTLS
    value: "False" # no TLS for local debug server
  - name: SMTP_SSL
    value: "False"
  - name: SMTP_USER
    value: ""
  - name: SMTP_PASSWORD
    value: ""
  - name: SMTP_MAIL_FROM
    value: "superset@test.local"
  
  # Auth0 OAuth2 Configuration
  # These credentials are also set as defaults in the oauth config section below
  # You can override them here or use Kubernetes secrets for production
  - name: AUTH0_DOMAIN
    value: "dev-vfdepkcc6kiv3sql.us.auth0.com"
  - name: AUTH0_CLIENT_ID
    value: "SMvMGKRDfQyTgGo8ZtqKYlCygNgeNZsY"
  - name: AUTH0_CLIENT_SECRET
    value: "kYdtViUEQmqnqcfWLZO0ozmN6crumfWz9jCRw3A0TtIBlswzdh-MCgNM3rMQu5_9"

# Bootstrap and initialize Superset database and admin user
init:
  # When enabled, Helm will create a Kubernetes Job to initialize Superset.
  # The Job runs database migrations and creates the initial admin user.
  # This is controlled by this 'enabled' flag.
  # enabled: true
  adminUser:
    # These values are passed as environment variables to the init Job.
    # Superset's init script uses them to create the admin user.
    # Superset Application user layer creation
    username: admin
    firstname: Superset
    lastname: Admin
    email: admin@superset.local
    password: admin1234

# Superset connection configuration
# These values tell Superset how to connect to PostgreSQL and Redis
supersetNode:
  connections:
    # Redis connection for caching and Celery
    redis_host: "{{ .Release.Name }}-redis-headless"
    redis_port: "6379"
    redis_password: superset
    # PostgreSQL connection for metadata
    db_host: "{{ .Release.Name }}-postgresql"
    db_port: "5432"
    db_user: superset
    db_pass: superset
    db_name: superset

# Celery Beat - not needed for user registration emails, but keep for future use
supersetCeleryBeat:
  enabled: true

# extraSecretEnv:
#   GLOBAL_ASYNC_QUERIES_JWT_SECRET: "mk73pMFjxG9IcUrVrAhFc2nT8XS5jG7AndThisIsALongerSecretForAsyncQueries12345"
#   JWT_SECRET: "mk73pMFjxG9IcUrVrAhFc2nT8XS5jG7AndThisIsALongerSecretForAsyncQueries12345"

configOverrides:
  # Secret key for encryption
  secret: |
    SECRET_KEY = "Iy6mTNpe8SaC7moVhtEO0fJH+STKk880l9DmK4MCKki+SAMoz8lyzbNR"

    # Query row limit
    ROW_LIMIT = 5000

    # Enable proxy fix
    ENABLE_PROXY_FIX = True

    # Enable async query execution
    FEATURE_FLAGS = {
        'GLOBAL_ASYNC_QUERIES': True,
    }

    # JWT secret for async query authentication (must be at least 32 bytes)
    GLOBAL_ASYNC_QUERIES_JWT_SECRET = "mk73pMFjxG9IcUrVrAhFc2nT8XS5jG7AndThisIsALongerSecretForAsyncQueries12345"

    # Rate limiting for API endpoints
    RATELIMIT_ENABLED = True

    # Default rate limits (requests per second)
    RATELIMIT_DEFAULT = "1000 per second"

    # Rate limiting storage (uses Redis DB 2 to avoid conflicts)
    # Reason: Rate limiting protects API endpoints from abuse and ensures fair resource usage
    RATELIMIT_STORAGE_URI = "redis://:superset@{{ .Release.Name }}-redis-master:6379/2"

    # reCAPTCHA Configuration (disabled by default)
    # Set to None or empty string to disable reCAPTCHA on login
    # To enable: get keys from https://www.google.com/recaptcha/admin
    RECAPTCHA_PUBLIC_KEY = None
    RECAPTCHA_PRIVATE_KEY = None

  # Auth0 OAuth2 Configuration (integrated with database auth)
  oauth: |
    import os
    from flask_appbuilder.security.manager import AUTH_OAUTH
    
    # Set authentication type to DATABASE (allows email/password login)
    # OAuth buttons will still appear alongside the login form
    AUTH_TYPE = AUTH_DB
    
    # Allow user self registration via OAuth
    # When False, only pre-existing users (created by admin) can login via OAuth
    # When True, new users can self-register via OAuth
    # AUTH_USER_REGISTRATION = True
    
    # Default role for self-registered users (via OAuth)
    # Options: Admin, Alpha, Gamma, Public
    AUTH_USER_REGISTRATION_ROLE = "Public"
    
    # Auth0 domain - replace with your actual Auth0 domain
    AUTH0_DOMAIN = os.getenv('AUTH0_DOMAIN', 'dev-vfdepkcc6kiv3sql.us.auth0.com')

    # OAuth Providers Configuration
    OAUTH_PROVIDERS = [
        {   
            'name': 'Auth0',
            'token_key': 'access_token',
            'icon': 'fa-address-card',
            'remote_app': {
                'client_id': os.getenv('AUTH0_CLIENT_ID', 'SMvMGKRDfQyTgGo8ZtqKYlCygNgeNZsY'),
                'client_secret': os.getenv('AUTH0_CLIENT_SECRET', 'kYdtViUEQmqnqcfWLZO0ozmN6crumfWz9jCRw3A0TtIBlswzdh-MCgNM3rMQu5_9'),
                'client_kwargs': {
                    'scope': 'openid email profile'
                },
                'access_token_method': 'POST',
                'access_token_params': {
                    'client_id': os.getenv('AUTH0_CLIENT_ID', 'SMvMGKRDfQyTgGo8ZtqKYlCygNgeNZsY')
                },
                'api_base_url': f'https://{AUTH0_DOMAIN}/',
                'access_token_url': f'https://{AUTH0_DOMAIN}/oauth/token',
                'authorize_url': f'https://{AUTH0_DOMAIN}/authorize',
                'jwks_uri': f'https://{AUTH0_DOMAIN}/.well-known/jwks.json',
                'server_metadata_url': f'https://{AUTH0_DOMAIN}/.well-known/openid-configuration',
            }
        }
    ]

  # Redis cache configuration
  cache: |
    # Configure Redis as the caching backend
    CACHE_CONFIG = {
        'CACHE_TYPE': 'RedisCache',
        'CACHE_DEFAULT_TIMEOUT': 300,
        'CACHE_KEY_PREFIX': 'superset_cache_',
        'CACHE_REDIS_HOST': '{{ .Release.Name }}-redis-master',
        'CACHE_REDIS_PORT': 6379,
        'CACHE_REDIS_PASSWORD': 'superset',
        'CACHE_REDIS_DB': 1,
    }

    # Data cache configuration (for chart data)
    DATA_CACHE_CONFIG = {
        'CACHE_TYPE': 'RedisCache',
        'CACHE_DEFAULT_TIMEOUT': 86400,  # 24 hours
        'CACHE_KEY_PREFIX': 'superset_data_',
        'CACHE_REDIS_HOST': '{{ .Release.Name }}-redis-master',
        'CACHE_REDIS_PORT': 6379,
        'CACHE_REDIS_PASSWORD': 'superset',
        'CACHE_REDIS_DB': 1,
    }

  # Celery configuration for async queries
  celery: |
    # Celery broker configuration (uses Redis DB 0)
    CELERY_CONFIG = {
        'broker_url': 'redis://:superset@{{ .Release.Name }}-redis-master:6379/0',
        'result_backend': 'redis://:superset@{{ .Release.Name }}-redis-master:6379/0',
        'worker_prefetch_multiplier': 1,
        'task_acks_late': False,
        'task_annotations': {
            'sql_lab.get_sql_results': {
                'rate_limit': '100/s',
            },
        },
    }

    # Additional Celery settings
    CELERY_ACCEPT_CONTENT = ['json']
    CELERY_TASK_SERIALIZER = 'json'
    CELERY_RESULT_SERIALIZER = 'json'
    CELERY_TIMEZONE = 'UTC'

    # Queue configuration
    from kombu import Queue
    CELERY_DEFAULT_QUEUE = 'superset'
    CELERY_QUEUES = (
        Queue('superset', routing_key='superset'),
    )

    # Task execution settings
    CELERY_TASK_TRACK_STARTED = True
    CELERY_TASK_TIME_LIMIT = 300  # 5 minutes timeout for async queries
    CELERY_TASK_SOFT_TIME_LIMIT = 270  # Soft timeout (90% of hard timeout)

    # SQL Lab async configuration
    SQLLAB_ASYNC_TIME_LIMIT_SEC = 300  # Must match CELERY_TASK_TIME_LIMIT
    SQLLAB_TIMEOUT = 300

  # Custom security manager for user registration emails
  custom_security: |
    import os
    import smtplib
    import logging
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from superset.security import SupersetSecurityManager
    from sqlalchemy import event

    # Setup logging
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    # SMTP/Email Configuration
    SMTP_HOST = os.getenv('SMTP_HOST', '192.168.100.111')
    SMTP_PORT = int(os.getenv('SMTP_PORT', '1025'))
    SMTP_STARTTLS = os.getenv('SMTP_STARTTLS', 'False') == 'True'
    SMTP_SSL = os.getenv('SMTP_SSL', 'False') == 'True'
    SMTP_USER = os.getenv('SMTP_USER', '')
    SMTP_PASSWORD = os.getenv('SMTP_PASSWORD', '')
    SMTP_MAIL_FROM = os.getenv('SMTP_MAIL_FROM', 'superset@test.local')

    # Enable password reset functionality
    ENABLE_PASSWORD_RESET = True

    logger.info(f"ðŸ“§ Email configuration loaded: SMTP_HOST={SMTP_HOST}, SMTP_PORT={SMTP_PORT}")
    print(f"ðŸ“§ Email configuration loaded: SMTP_HOST={SMTP_HOST}, SMTP_PORT={SMTP_PORT}")

    def send_welcome_email(user):
        """Send welcome email to new user"""
        try:
            username = user.username
            first_name = user.first_name
            last_name = user.last_name
            email = user.email
            roles = user.roles if hasattr(user, 'roles') else []
            
            if not email:
                logger.warning(f"âš ï¸ No email address for user {username}, skipping email")
                return False
            
            logger.info(f"ðŸ“¨ Attempting to send welcome email to {email}")
            print(f"ðŸ“¨ Attempting to send welcome email to {email}")
            
            # Create email message
            msg = MIMEMultipart()
            msg['Subject'] = "Welcome to Superset!"
            msg['From'] = SMTP_MAIL_FROM
            msg['To'] = email
            
            # Email body
            role_names = ', '.join([r.name for r in roles]) if roles else 'User'
            body = f"""Hello {first_name or username},

    Your Superset account has been created successfully!

    Username: {username}
    Email: {email}
    Role(s): {role_names}

    # This will be later changed to the actual URL of the Superset instance
    You can log in at: http://superset.local:8088

    Enjoy exploring your data!

    Best regards,
    The Superset Team
    """
            msg.attach(MIMEText(body, 'plain'))
            
            # Send email using SMTP
            logger.info(f"ðŸ”Œ Connecting to SMTP server {SMTP_HOST}:{SMTP_PORT}")
            print(f"ðŸ”Œ Connecting to SMTP server {SMTP_HOST}:{SMTP_PORT}")
            
            if SMTP_SSL:
                server = smtplib.SMTP_SSL(SMTP_HOST, SMTP_PORT, timeout=10)
            else:
                server = smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=10)
            
            if SMTP_STARTTLS and not SMTP_SSL:
                logger.info("ðŸ” Starting TLS")
                server.starttls()
            
            if SMTP_USER and SMTP_PASSWORD:
                logger.info(f"ðŸ”‘ Logging in as {SMTP_USER}")
                server.login(SMTP_USER, SMTP_PASSWORD)
            
            server.send_message(msg)
            server.quit()
            
            logger.info(f"âœ… Welcome email sent successfully to {email}")
            print(f"âœ… Welcome email sent to {email}")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to send welcome email: {str(e)}", exc_info=True)
            print(f"âŒ Failed to send welcome email: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    # Event listener for new user creation
    def user_after_insert_listener(mapper, connection, target):
        """Triggered when a new user is inserted into the database"""
        logger.info(f"ðŸ‘¤ SQLAlchemy event: User created - {target.username}")
        print(f"ðŸ‘¤ SQLAlchemy event: User created - {target.username}")

        # Send email in background to avoid blocking the insert
        try:
            send_welcome_email(target)
        except Exception as e:
            logger.error(f"Error in user_after_insert_listener: {e}")
            print(f"Error in user_after_insert_listener: {e}")

    # Custom Security Manager
    class CustomSecurityManager(SupersetSecurityManager):
        def __init__(self, appbuilder):
            super().__init__(appbuilder)
            logger.info("ðŸ”§ CustomSecurityManager initialized!")
            print("ðŸ”§ CustomSecurityManager initialized!")
            
            # Register SQLAlchemy event listener for User inserts
            logger.info("ðŸŽ¯ Registering SQLAlchemy after_insert event for User model")
            print("ðŸŽ¯ Registering SQLAlchemy after_insert event for User model")
            event.listen(self.user_model, 'after_insert', user_after_insert_listener)

    # Register custom security manager
    CUSTOM_SECURITY_MANAGER = CustomSecurityManager

    logger.info("âœ… CustomSecurityManager registered")
    print("âœ… CustomSecurityManager registered in config")

# Bootstrap script - runs before Superset starts
# Installs additional packages needed for Superset
# This is need in order to use the Superser version 6.0.0 and Chart 0.15.0
bootstrapScript: |
  #!/bin/bash
  apt update && apt install -y gcc libpq-dev python3-dev pkg-config
  echo "installing required libs"
  uv pip install psycopg2-binary authlib
  if [ ! -f ~/bootstrap ]; then echo "Running Superset with uid {{ .Values.runAsUser }}" > ~/bootstrap; fi

# PostgreSQL for metadata storage
postgresql:
  # To overwrite the image
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: latest
    # When in dev use:
    # registry: 806137713344.dkr.ecr.eu-west-1.amazonaws.com
    # repository: bitnami/postgresql
    # tag: sha25672c84b3980dc0f90f5e5e4470554e8994d3d2a60f622318dd29ad23b3ebf5b44
  # Enable PostgreSQL (required for Superset metadata storage)
  enabled: true
  auth:
    # Username for the application database user (used by Superset to connect)
    # This creates a non-superuser account for Superset
    username: superset
    # Password for the application user
    password: superset
    # Database name to create for Superset
    # Superset will store its metadata (dashboards, users, etc.) here
    database: superset
    # Password for the PostgreSQL superuser (postgres)
    # Required for administrative tasks and initial setup
    # postgresPassword: superset123
  primary:
    persistence:
      # Enable persistent storage for PostgreSQL data
      # Prevents data loss when pods restart
      enabled: true
      # Size of the persistent volume
      size: 8Gi

# Redis for caching and Celery task queue
redis:
  # Enable Redis (required for Superset caching and async tasks)
  enabled: true
  image:
    registry: docker.io
    repository: bitnami/redis
    tag: latest
    # When in dev use:
    # registry: 806137713344.dkr.ecr.eu-west-1.amazonaws.com
    # repository: bitnami/redis
    # tag: sha256-142ab4d0c251bcf5466fffd33766350af718a6725cb926710be19fad00b2b035
  # Redis authentication configuration
  auth:
    # Enable password authentication
    enabled: true
    # Password for Redis - must match what Superset expects
    # The Superset chart will automatically configure this
    password: superset
  master:
    persistence:
      # Enable persistent storage for Redis data
      # Stores cached data and Celery task queue across restarts
      enabled: true
      # Size of the persistent volume
      size: 8Gi

# Resource limits for k3d cluster
resources:
  requests:
    # Minimal CPU guaranteed for Superset pod
    # Reason: Ensures the pod always has 100m (0.1 CPU) available on the node.
    cpu: 100m
    # Minimal memory guaranteed for Superset pod
    # Reason: Ensures the pod has enough memory to avoid out-of-memory errors.
    memory: 512Mi
  limits:
    # Max CPU available to the Superset pod
    # Reason: Prevents the pod from using more than 1 CPU core.
    cpu: 1000m
    # Max memory for the pod
    # Reason: Prevents pod from consuming more than 1Gi memory, protecting the node from overuse.
    memory: 1Gi

# Additional worker resources
supersetWorker:
  # Override the default command to add -E flag (enable events for monitoring)
  # Reason: The -E flag enables Celery events, which allows monitoring tools like Flower
  # to track worker activity and task execution in real-time
  # Using --uid=superset tells Celery to drop privileges and run as the 'superset' user
  # Concurrency reduced to 4 to prevent OOMKilled errors (default is 10)
  command:
    - "/bin/sh"
    - "-c"
    - ". /app/pythonpath/superset_bootstrap.sh; celery --app=superset.tasks.celery_app:app worker -E --uid=superset --concurrency=4"
  resources:
    requests:
      # CPU guaranteed for Celery worker pods
      # Reason: Ensures stable resource allocation for background task processing.
      cpu: 200m
      # Minimal memory guaranteed for worker pods.
      # Increased due to bootstrap script installing packages and Celery worker processes
      memory: 1Gi
    limits:
      # Max CPU for worker pods
      cpu: 1000m
      # Max memory for worker pods
      # Reason: Bootstrap script (apt install gcc, python-dev) + Celery prefork workers
      # require significant memory. 2.5Gi provides headroom for 10 concurrent workers.
      memory: 2560Mi

# Disable default ingress (using Traefik IngressRoute instead)
ingress:
  # Disables the default ingress created by the Helm chart
  # Reason: Allows using a custom IngressRoute (Traefik) defined elsewhere in the deployment.
  enabled: false

# Security context
# Run pod as root user (UID 0)
# Reason: Sometimes necessary for custom images or needing special permissions,
# but generally consider using a non-root user for better security.
runAsUser: 0
